{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "97099a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import words\n",
    "import fitz\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "45fb96b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to path that contains the PDFs\n",
    "path = r\"C:\\Users\\AbdulrahmanI\\Downloads\"\n",
    "# change to path that will contain the output files\n",
    "output_path = r\"C:\\Users\\AbdulrahmanI\\Downloads\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "15cc3c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(directory):\n",
    "    file_list = [file for file in os.listdir(path)\n",
    "             if os.path.isfile(os.path.join(path, file))]\n",
    "    file_list = [f for f in filter(lambda f: f.endswith(('.pdf','.PDF')), file_list)]\n",
    "    return file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "f3489a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rest_of_pages(text):\n",
    "    '''\n",
    "    Tokenizes and filters words of the page being compared to the most updated change notice page.\n",
    "    Parameters: text: the extracted text from the page being compared to the most updated change notice page.\n",
    "    Returns: filtered_other_pages: set of words filtered out with stop words of the page being compared\n",
    "    to the most updated change notice page\n",
    "    boolean_val: a boolean value that identifies if a page contains a keyword\n",
    "    '''\n",
    "    # removes all phone numbers from documents\n",
    "    remove_phone = re.sub(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]', \"\", text)\n",
    "    word_list = word_tokenize(remove_phone)\n",
    "    # checks if page is a change notice if it contains the keyword \"SUMMARY\"\n",
    "    if \"SUMMARY\" in word_list:\n",
    "        boolean_val = True\n",
    "        # removes top left text of older templates\n",
    "        if \"CONTRACT\" in word_list:\n",
    "            inde = word_list.index(\"CONTRACT\")\n",
    "            word_list = word_list[inde:]\n",
    "            # if contains these keywords, remove the agency details section to increase similarity\n",
    "            if \"PRIMARY\" and \"CONTACT\" in word_list:\n",
    "                ind = word_list.index('AGENCY')\n",
    "                del word_list[ind+1:ind+20]\n",
    "                del word_list[ind-2:ind+1]\n",
    "    else:\n",
    "        if \"TELEPHONE\" in word_list:\n",
    "            boolean_val = True\n",
    "        else:\n",
    "            boolean_val = False\n",
    "    filtered_other_pages = {word.lower() for word in word_list if word not in stopwords.words('english')}\n",
    "    return filtered_other_pages, boolean_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "b869dbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculation(filtered_first_pg, filtered_other_pages):\n",
    "    '''\n",
    "    Calculates the cosine similarity between the identified most updated change notice page and the other page.\n",
    "    Parameters: filtered_first_pg: keywords contained in the most updated change notice\n",
    "    filtered_other_pages: keywords contained in the other page\n",
    "    Returns: cosine similarity between the two pages\n",
    "    '''\n",
    "    l1 = []\n",
    "    l2 = []\n",
    "    # forms a set containing keywords of both strings \n",
    "    rvector = filtered_first_pg.union(filtered_other_pages)\n",
    "    for w in rvector:\n",
    "        if w in filtered_first_pg: \n",
    "            l1.append(1) # creates a vector/matrix\n",
    "        else: \n",
    "            l1.append(0)\n",
    "        if w in filtered_other_pages: \n",
    "            l2.append(1)\n",
    "        else: \n",
    "            l2.append(0)\n",
    "    c = 0\n",
    "    # cosine similarity formula \n",
    "    for i in range(len(rvector)):\n",
    "            c+= l1[i]*l2[i]\n",
    "    try:\n",
    "        cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "    except ZeroDivisionError:\n",
    "        return 0\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5bf26b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_file(cosine, text, new_file, boolean_val):\n",
    "    '''\n",
    "    Writes to a new file if under the identified threshold.\n",
    "    Parameters: cosine: cosine similarity between the two pages being compared\n",
    "    text: page being compared to the most updated change notice\n",
    "    new_file: file to write to\n",
    "    boolean_val: a boolean value that identifies if a page contains the keyword \"SUMMARY\"\n",
    "    Returns: None\n",
    "    '''\n",
    "    if boolean_val == True:\n",
    "        if cosine >= 0.38:\n",
    "            pass\n",
    "        else:\n",
    "            new_file.write(text)\n",
    "    else:\n",
    "        new_file.write(text)\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a79dc4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def page_by_page(doc, first_pg, text, new_file):\n",
    "    '''\n",
    "    Iterates through each page in the PDF document, extracting text and ignoring any outdated\n",
    "    change notice page.\n",
    "    Parameters: doc: entire readable PDF document \n",
    "    first_pg: empty string\n",
    "    text: empty string\n",
    "    new_file: file to write to\n",
    "    Returns: None\n",
    "    '''\n",
    "    for page in doc:\n",
    "        if first_pg != \"\":\n",
    "            text = \"\"\n",
    "            text = page.get_text()\n",
    "            lis = [i for i in text.split('\\n') if i]\n",
    "            #print(tokens)\n",
    "            for ele in lis:\n",
    "                if ele == \" \":\n",
    "                    lis.remove(ele)\n",
    "            lis = [ele.strip(' ') for ele in lis]\n",
    "            #print(tokens)\n",
    "            text = ' '.join(lis)\n",
    "            text = \" \".join(text.split())\n",
    "            text += ' '\n",
    "            filtered_other_pages, boolean_val = rest_of_pages(text)\n",
    "        else:\n",
    "            first_pg += page.get_text()\n",
    "            # splits all newline ('\\n') characters\n",
    "            tokens = [i for i in first_pg.split('\\n') if i]\n",
    "            #print(tokens)\n",
    "            for token in tokens:\n",
    "                if token == \" \":\n",
    "                    tokens.remove(token)\n",
    "            tokens = [x.strip(' ') for x in tokens]\n",
    "            #print(tokens)\n",
    "            first_pg = ' '.join(tokens)\n",
    "            first_pg = \" \".join(first_pg.split())\n",
    "            first_pg += ' '\n",
    "            #print(first_pg)\n",
    "            if first_pg.find(\"SUMMARY\") != -1:\n",
    "                new_file.write(first_pg)\n",
    "            else:\n",
    "                new_file.write(first_pg)\n",
    "                first_pg = \"\"\n",
    "                continue\n",
    "            # removes all phone numbers from documents\n",
    "            remove_phone = re.sub(r'[\\+\\(]?[1-9][0-9 .\\-\\(\\)]{8,}[0-9]', \"\", first_pg)\n",
    "            word_list = word_tokenize(remove_phone)\n",
    "            # removes stop words from word_list\n",
    "            filtered_first_pg = {word.lower() for word in word_list if word not in stopwords.words('english')}\n",
    "            continue\n",
    "        cosine = calculation(filtered_first_pg, filtered_other_pages)\n",
    "        written = write_to_file(cosine, text, new_file, boolean_val)\n",
    "        continue\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "84bf5468",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3.34 s\n",
      "Wall time: 3.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def main():\n",
    "    file_list = get_files(path)\n",
    "    for file_name in file_list:\n",
    "        try:\n",
    "            file_path = os.path.join(output_path, file_name[:-4])\n",
    "            new_file = open(file_path + \".txt\", \"w\", encoding='utf8')           \n",
    "            with fitz.open(path+'/' + file_name) as doc:\n",
    "                first_pg = \"\"\n",
    "                text = \"\"\n",
    "                result = page_by_page(doc, first_pg, text, new_file)\n",
    "        except RuntimeError:\n",
    "            continue\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c1d99e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
