{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf87831",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import fitz\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116bf6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8969c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import fitz\n",
    "import re\n",
    "\n",
    "dir_path = \"/Users/ilyasabdulrahman/Desktop/work_docs/some_docs\"\n",
    "os.chdir(dir_path)\n",
    "file_list = os.listdir()\n",
    "\n",
    "count = 1\n",
    "for file_name in file_list:\n",
    "    try:\n",
    "        new_file = open(\"doc\" + str(count) + \".txt\", \"w\")\n",
    "        with fitz.open(dir_path+'/' + file_name) as doc:\n",
    "            first_pg = \"\"\n",
    "            text = \"\"\n",
    "            # loops through each page and removes all stop words\n",
    "            for page in doc:\n",
    "                date_pattern='(Jan(uary)?|Feb(ruary)?|Mar(ch)?|Apr(il)?|May|Jun(e)?|Jul(y)?|Aug(ust)?|Sep(tember)?|Oct(ober)?|Nov(ember)?|Dec(ember)?)\\s+\\d{1,2},\\s+\\d{4}'\n",
    "                if first_pg != \"\":\n",
    "                    text = \"\"\n",
    "                    text = page.get_text()\n",
    "                    # removes all patterns of dates\n",
    "                    new_text = re.sub(date_pattern, \"\", text)\n",
    "                    # removes all names\n",
    "                    nt = re.sub(r\"[A-Z][a-z]+,?\\s+(?:[A-Z][a-z]*\\.?\\s*)?[A-Z][a-z]+\", \"\", new_text)\n",
    "                    word_list = word_tokenize(nt)\n",
    "                    # removes stop words from word_list\n",
    "                    filtered_words2 = {word.lower() for word in word_list if word not in stopwords.words('english')}\n",
    "                else:\n",
    "                    first_pg += page.get_text()\n",
    "                    # removes all patterns of dates\n",
    "                    new_first = re.sub(date_pattern, \"\", first_pg)\n",
    "                    # writes to new file if first_pg contains \"Change Notice\"\n",
    "                    if first_pg.find(\"Change Notice\") != -1:\n",
    "                        new_file.write(first_pg)\n",
    "                    # removes all names\n",
    "                    nf = re.sub(r\"[A-Z][a-z]+,?\\s+(?:[A-Z][a-z]*\\.?\\s*)?[A-Z][a-z]+\", \"\", new_first)\n",
    "                    word_list = word_tokenize(nf)\n",
    "                    # removes stop words from word_list\n",
    "                    filtered_words1 = {word.lower() for word in word_list if word not in stopwords.words('english')}\n",
    "                    continue\n",
    "                l1 = []\n",
    "                l2 = []\n",
    "                # forms a set containing keywords of both strings \n",
    "                rvector = filtered_words1.union(filtered_words2)\n",
    "                for w in rvector:\n",
    "                    if w in filtered_words1: l1.append(1) # creates a vector/matrix\n",
    "                    else: l1.append(0)\n",
    "                    if w in filtered_words2: l2.append(1)\n",
    "                    else: l2.append(0)\n",
    "                c = 0\n",
    "                # cosine formula \n",
    "                for i in range(len(rvector)):\n",
    "                        c+= l1[i]*l2[i]\n",
    "                cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "                # only writes to new file if not within the threshold\n",
    "                if cosine >= 0.40:\n",
    "                    pass\n",
    "                else:\n",
    "                    new_file.write(text)\n",
    "        # increments counter to write to separate file for each pdf document\n",
    "        count += 1\n",
    "        new_file.close()\n",
    "        doc.close()\n",
    "    except:\n",
    "        continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
